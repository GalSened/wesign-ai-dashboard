# WeSign AI Assistant - Complete Documentation

ğŸ¤– **Intelligent Multi-Agent System for Document Management & Digital Signatures**

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![AutoGen 0.7.5](https://img.shields.io/badge/AutoGen-0.7.5-green.svg)](https://microsoft.github.io/autogen/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-009688.svg)](https://fastapi.tiangolo.com/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4-412991.svg)](https://openai.com/)

## ğŸŒŸ Overview

WeSign AI Assistant is a sophisticated multi-agent orchestration system built with AutoGen v0.7.5, featuring **native MCP (Model Context Protocol) integration**, **voice-to-text capabilities**, and **official OpenAI ChatKit Python SDK** for seamless AI-powered document workflows.

### Key Features

âœ… **5 Specialized AI Agents** - Document, Signing, Template, Admin, and FileSystem agents
âœ… **Native MCP Integration** - AutoGen v0.7.5 with built-in MCP protocol support
âœ… **14 FileSystem Tools** - Secure local file operations with MCP
âœ… **WeSign MCP Server** - HTTP-based MCP for document operations (configurable)
âœ… **Voice-to-Text** - OpenAI Whisper API integration for voice commands
âœ… **OpenAI GPT-4** - Powered by state-of-the-art language model
âœ… **Official ChatKit Python SDK** - OpenAI's official ChatKit server implementation
âœ… **Modern Web UI** - Responsive chat interface with real-time agent interaction
âœ… **RESTful API** - FastAPI with automatic OpenAPI documentation

---

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     WeSign AI Assistant                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  ChatKit UI    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   FastAPI Backend       â”‚    â”‚
â”‚  â”‚  :8000/ui      â”‚         â”‚   Port 8000             â”‚    â”‚
â”‚  â”‚  + Voice ğŸ¤    â”‚         â”‚   + Whisper API         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                          â”‚                    â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚                              â”‚  WeSign Orchestrator    â”‚    â”‚
â”‚                              â”‚  + Native MCP           â”‚    â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                          â”‚                    â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”
â”‚          â”‚  5 AI Agents    â”‚  â”‚  OpenAI      â”‚  â”‚   MCP   â”‚
â”‚          â”‚  (Specialists)  â”‚  â”‚  GPT-4       â”‚  â”‚ Servers â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚               â”‚ Agent Routing                    â”œâ”€ FileSystem (14 tools)
â”‚               â”‚                                  â””â”€ WeSign (HTTP)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Native MCP Integration âœ¨

**Migrated from custom MCP client to AutoGen native MCP:**

```python
# âœ… NEW: Native AutoGen MCP (orchestrator_new.py)
from autogen_ext.tools.mcp import StdioServerParams, StreamableHttpServerParams, mcp_server_tools

# FileSystem MCP (stdio-based)
filesystem_params = StdioServerParams(
    command="npx",
    args=["-y", "@modelcontextprotocol/server-filesystem"] + allowed_dirs
)
tools = await mcp_server_tools(filesystem_params)

# WeSign MCP (HTTP-based)
wesign_params = StreamableHttpServerParams(url="http://localhost:3000")
wesign_tools = await mcp_server_tools(wesign_params)

# Attach to agents
agent = AssistantAgent(tools=tools)
```

**Benefits:**
- âš¡ Automatic tool discovery and registration
- ğŸ”’ Type-safe tool execution
- ğŸ› ï¸ Built-in error handling
- ğŸ“¦ Simpler architecture
- ğŸš€ Better performance
- ğŸŒ Support for both stdio and HTTP-based MCP servers

### Official OpenAI ChatKit Integration ğŸ¯

**Production-ready chat interface powered by OpenAI's ChatKit Python SDK:**

The system integrates the official `openai-chatkit` package for enterprise-grade chat functionality:

**Backend Architecture:**
```python
# chatkit_server.py - Official ChatKit Server Implementation
from chatkit.server import ChatKitServer
from chatkit.types import ThreadStreamEvent, UserMessageItem, AssistantMessageItem

class WeSignChatKitServer(ChatKitServer):
    """ChatKit server that bridges to AutoGen multi-agent orchestrator"""

    async def respond(self, thread, input_user_message, context):
        # Process through AutoGen orchestrator
        result = await self.orchestrator.process_message(...)

        # Stream back via ChatKit events
        yield ThreadItemAddedEvent(item=assistant_item)
        yield ThreadItemDoneEvent(item=assistant_item)
```

**Frontend Options:**

1. **Official ChatKit UI** (Current Implementation)
   - Location: `frontend/official-chatkit.html`
   - CDN: `https://cdn.platform.openai.com/deployments/chatkit/chatkit.js`
   - Access: http://localhost:8000/ui

2. **React ChatKit** (Alternative for Advanced Features)
   - Package: `@openai/chatkit-react`
   - Best for: Custom servers with complex workflows
   - Installation: `npm install @openai/chatkit-react`

**Key Components:**

| Component | Purpose | Location |
|-----------|---------|----------|
| `chatkit_server.py` | ChatKit server implementation | orchestrator/ |
| `chatkit_store.py` | Conversation persistence | orchestrator/ |
| `official-chatkit.html` | Official ChatKit UI | frontend/ |
| `/chatkit` endpoint | ChatKit communication (SSE) | main.py:281 |
| `/ui` endpoint | Serve ChatKit UI | main.py:147 |

**Communication Flow:**

```
User Message â†’ ChatKit UI â†’ /chatkit endpoint â†’ ChatKitServer.respond()
â†’ AutoGen Orchestrator â†’ AI Agents â†’ MCP Tools â†’ Response Stream
â†’ Server-Sent Events â†’ ChatKit UI â†’ User
```

**Features:**
- âœ… Real-time streaming responses via SSE
- âœ… Thread-based conversation management
- âœ… File upload support
- âœ… Tool call visibility
- âœ… Multi-agent orchestration
- âœ… Persistent conversation history

**Official Documentation:**
- [ChatKit Python SDK](https://openai.github.io/chatkit-python/server/)
- [ChatKit JavaScript](https://openai.github.io/chatkit-js/)
- [ChatKit Authentication](https://openai.github.io/chatkit-js/guides/authentication)

---

## âœ¨ Features

### 1. Multi-Agent System (5 Specialists)

| Agent | Purpose | MCP Tools |
|-------|---------|-----------|
| **DocumentAgent** | Upload, list, manage documents | WeSign MCP |
| **SigningAgent** | Create & complete digital signatures | WeSign MCP |
| **TemplateAgent** | Manage and use document templates | WeSign MCP |
| **AdminAgent** | General assistance and guidance | None |
| **FileSystemAgent** | Browse and select local files | FileSystem MCP (14 tools) |

### 2. Voice-to-Text Integration ğŸ¤

**OpenAI Whisper API-powered voice commands:**

- ğŸ™ï¸ Click microphone button to record voice
- ğŸ”Š Speak your command naturally
- âœ… Auto-transcription using Whisper API
- ğŸ“ Text appears in input field for review/edit
- ğŸš€ Send transcribed message to AI assistant

**Supported Audio Formats:**
- WAV, MP3, MP4, M4A, MPEG, MPGA, WEBM
- Maximum file size: 25MB

**Voice Flow:**
```
User Voice â†’ MediaRecorder API â†’ Audio Blob â†’ /api/speech-to-text
â†’ OpenAI Whisper API â†’ Transcribed Text â†’ Input Field â†’ User Review â†’ Send
```

**Browser Requirements:**
- Chrome 47+, Firefox 25+, Edge 79+, Safari 14.1+
- HTTPS connection (or localhost for development)
- Microphone permissions

**See**: `VOICE_FEATURE_DOCUMENTATION.md` for complete implementation details

### 3. FileSystem MCP Tools (14 Available)

Secure file system operations:

- `list_allowed_directories` - Show accessible directories
- `list_directory` - List directory contents
- `read_file` - Read file contents
- `read_multiple_files` - Batch file reading
- `write_file` - Create/update files
- `create_directory` - Create new directories
- `move_file` - Move/rename files
- `search_files` - Search by pattern
- `get_file_info` - Get file metadata
- ... and 5 more!

**Security**: Only accesses allowed directories:
- `~/Documents`
- `~/Downloads`
- `/tmp/wesign-assistant`

### 4. WeSign MCP Server (HTTP-based) ğŸŒ

**Configuration:**
- Server URL: `http://localhost:3000` (configurable via `WESIGN_MCP_URL`)
- Protocol: HTTP with StreamableHttpServerParams
- Graceful fallback when server unavailable
- Ready for document operations, signing workflows, template management

**Status**: Enabled and ready for testing (start WeSign MCP server to activate tools)

### 5. Intelligent Agent Selection

Automatic routing based on user intent:

```python
"List files in Documents" â†’ FileSystemAgent
"Sign this document" â†’ SigningAgent
"Show my templates" â†’ TemplateAgent
"Help me get started" â†’ AdminAgent
```

---

## ğŸ“¦ Prerequisites

- **Python 3.9+** (3.12 recommended)
- **Node.js 16+** (for MCP FileSystem server)
- **OpenAI API Key** (required)
- **4GB RAM** (8GB recommended)
- **Modern web browser** (for voice features)

---

## ğŸš€ Quick Start

### 1. Clone & Setup

```bash
cd /path/to/your/projects
git clone <repository-url>
cd wesign-ai-dashboard/orchestrator

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure Environment

```bash
# Copy environment template
cp .env.example .env

# Edit .env and add your OpenAI API key
nano .env  # or vim/code .env
```

**Required configuration:**

```bash
# OpenAI Configuration (REQUIRED)
OPENAI_API_KEY=sk-proj-YOUR-KEY-HERE

# FileSystem MCP Configuration
FILESYSTEM_ALLOWED_DIRS=$HOME/Documents,$HOME/Downloads,/tmp/wesign-assistant

# WeSign MCP Configuration (Optional - for document operations)
WESIGN_MCP_URL=http://localhost:3000

# Server Configuration
HOST=0.0.0.0
PORT=8000
```

### 3. Start the System

**Option A: Use startup script (recommended)**

```bash
cd /path/to/wesign-ai-dashboard
./scripts/start-all.sh
```

**Option B: Manual start**

```bash
cd orchestrator
source venv/bin/activate
python main.py
```

**Expected Output:**
```
ğŸ¤– Initializing AutoGen agents with native MCP...
ğŸ”§ Initializing WeSign MCP server...
ğŸ“¡ Connecting to WeSign MCP at: http://localhost:3000
âš ï¸  WeSign MCP unavailable - continuing with 0 tools (start WeSign server to enable)
ğŸ—‚ï¸  Initializing FileSystem MCP server...
âœ… FileSystem MCP: 14 tools available
ğŸ“ Allowed directories: ['/Users/you/Documents', '/Users/you/Downloads', '/tmp/wesign-assistant']
âœ… Initialized 5 agents with 2 MCP tool categories
ğŸš€ Starting FastAPI server...
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

### 4. Access the Application

- **ğŸŒ ChatKit UI**: http://localhost:8000/ui
- **ğŸ¥ Health Check**: http://localhost:8000/health
- **ğŸ“š API Docs**: http://localhost:8000/docs
- **ğŸ”§ API Root**: http://localhost:8000/

---

## ğŸ¯ Usage Examples

### Web UI (ChatKit)

Open http://localhost:8000/ui in your browser and try:

```
ğŸ’¬ "List files in my Documents folder"
ğŸ’¬ "Read the first 20 lines of README.md in Downloads"
ğŸ’¬ "Help me sign a document"
ğŸ’¬ "Show me available templates"
ğŸ’¬ "What can you help me with?"
```

**Voice Input:**
1. Click microphone button ğŸ¤
2. Allow microphone permissions
3. Speak your command
4. Click stop button â¹ï¸
5. Review transcribed text
6. Click send or press Enter

### API Usage

**Health Check:**
```bash
curl http://localhost:8000/health
```

**Response:**
```json
{
  "status": "healthy",
  "version": "2.0.0-native-mcp",
  "mcp_integration": "native_autogen",
  "agents": {
    "total_agents": 5,
    "agents": ["document", "signing", "template", "admin", "filesystem"],
    "conversations": 0,
    "mcp_tools": {
      "wesign": 0,
      "filesystem": 14
    }
  }
}
```

**Send Chat Message:**
```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "List files in my Documents",
    "context": {
      "userId": "user-123",
      "companyId": "company-456",
      "userName": "John Doe"
    }
  }'
```

**List Available Tools:**
```bash
curl http://localhost:8000/api/tools
```

**Response:**
```json
{
  "count": 14,
  "categories": {
    "wesign": 0,
    "filesystem": 14
  },
  "integration_type": "native_autogen_mcp",
  "tools": {
    "filesystem": [
      "list_allowed_directories",
      "list_directory",
      "read_file",
      "read_multiple_files",
      "write_file",
      "create_directory",
      "move_file",
      "search_files",
      "get_file_info",
      "..."
    ]
  }
}
```

**Voice Transcription:**
```bash
# Record audio file first, then:
curl -X POST http://localhost:8000/api/speech-to-text \
  -H "Content-Type: multipart/form-data" \
  -F "file=@recording.wav"
```

**Response:**
```json
{
  "text": "List files in my Documents folder",
  "filename": "recording.wav",
  "size": 123456
}
```

---

## ğŸ“¡ API Documentation

### Core Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Service info and status |
| `/health` | GET | Health check with agent status |
| `/ui` | GET | Serve ChatKit UI |
| `/official-chatkit.html` | GET | Serve official OpenAI ChatKit UI |
| `/api/chat` | POST | Send message to AI assistant |
| `/api/speech-to-text` | POST | Voice-to-text transcription (Whisper API) |
| `/api/tools` | GET | List available MCP tools |
| `/api/upload` | POST | Upload file for processing |
| `/api/chatkit/session` | POST | Create ChatKit authentication session |
| `/api/chatkit-client-token` | POST | Legacy ChatKit token endpoint |
| `/api/chatkit-status` | GET | ChatKit server statistics |
| `/chatkit` | ALL | ChatKit communication endpoint (SSE) |
| `/docs` | GET | OpenAPI documentation |

### Chat API Request

```json
{
  "message": "string",
  "context": {
    "userId": "string",
    "companyId": "string",
    "userName": "string",
    "conversationId": "string (optional)"
  },
  "files": [
    {
      "fileId": "string",
      "fileName": "string",
      "filePath": "string"
    }
  ]
}
```

### Chat API Response

```json
{
  "response": "string",
  "conversationId": "string",
  "toolCalls": [
    {
      "tool": "string",
      "action": "string",
      "parameters": {},
      "result": "string"
    }
  ],
  "metadata": {
    "agent": "string",
    "user_name": "string",
    "files_count": 0
  }
}
```

### Speech-to-Text API

**Request:**
- Method: POST
- Content-Type: multipart/form-data
- Body: `file` (audio file)

**Response:**
```json
{
  "text": "Transcribed text from audio",
  "filename": "recording.wav",
  "size": 12345
}
```

**Errors:**
- 400: File too large (max 25MB) or empty file
- 500: Transcription failed (check OPENAI_API_KEY)

---

## ğŸ”’ Security

### FileSystem MCP Security

- âœ… **Sandboxed Access**: Only allowed directories are accessible
- âœ… **Path Validation**: All paths are validated before access
- âœ… **No System Directories**: Cannot access `/etc`, `/usr`, `/var`
- âœ… **User Confirmation**: FileSystemAgent confirms paths with users

### Configuration Best Practices

```bash
# âœ… GOOD: Specific user directories
FILESYSTEM_ALLOWED_DIRS=$HOME/Documents,$HOME/Downloads

# âŒ BAD: System directories
FILESYSTEM_ALLOWED_DIRS=/etc,/usr,/var

# âŒ BAD: Root directory
FILESYSTEM_ALLOWED_DIRS=/
```

### API Key Security

- âœ… Store API keys in `.env` (never commit to git)
- âœ… Add `.env` to `.gitignore`
- âœ… Use environment variables in production
- âœ… Rotate keys regularly
- âœ… Voice transcriptions processed server-side (API key never exposed to frontend)

### Voice Feature Security

- âœ… Temporary audio files created in isolated directory
- âœ… Automatic cleanup after transcription
- âœ… Path validation prevents directory traversal
- âœ… OpenAI API key stored server-side only
- âœ… No audio data logged or persisted

---

## ğŸ› ï¸ Development

### Project Structure

```
wesign-ai-dashboard/
â”œâ”€â”€ orchestrator/               # Main FastAPI application
â”‚   â”œâ”€â”€ main.py                # FastAPI server & routes
â”‚   â”œâ”€â”€ orchestrator_new.py    # AutoGen orchestrator with native MCP
â”‚   â”œâ”€â”€ chatkit_server.py      # ChatKit integration
â”‚   â”œâ”€â”€ chatkit_store.py       # ChatKit storage
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ .env                   # Environment variables (gitignored)
â”‚   â”œâ”€â”€ .env.example           # Environment template
â”‚   â””â”€â”€ venv/                  # Python virtual environment
â”œâ”€â”€ frontend/                   # Web UI
â”‚   â”œâ”€â”€ official-chatkit.html  # Official OpenAI ChatKit UI
â”‚   â””â”€â”€ chatkit-index.html     # Legacy custom UI (deprecated)
â”œâ”€â”€ scripts/                    # Utility scripts
â”‚   â”œâ”€â”€ start-all.sh           # Complete startup script
â”‚   â””â”€â”€ start-filesystem-mcp.sh # FileSystem MCP standalone
â”œâ”€â”€ tests/                      # Test suites
â”‚   â””â”€â”€ e2e/                   # End-to-end tests
â”‚       â””â”€â”€ wesign-assistant.spec.js  # Playwright E2E tests
â”œâ”€â”€ VOICE_FEATURE_DOCUMENTATION.md  # Voice feature details
â”œâ”€â”€ TEST_RESULTS_REPORT.md     # MCP testing evidence
â””â”€â”€ README.md                   # This file
```

### Key Files Explained

**orchestrator_new.py** (436 lines):
- WeSignOrchestrator class with native MCP
- 5 specialized agent creation methods
- MCP server initialization (FileSystem + WeSign)
- Message processing and agent routing
- Tool call extraction and response formatting

**main.py** (700+ lines):
- FastAPI application setup
- All API endpoints
- ChatKit integration endpoints
- Voice transcription endpoint
- File upload handling
- Health checks and monitoring

**chatkit_server.py**:
- WeSignChatKitServer class
- OpenAI ChatKit server implementation
- AutoGen orchestrator bridge
- Server-sent events streaming

**chatkit_store.py**:
- In-memory conversation storage (dev-only)
- Thread and message management
- User context tracking

### Testing

**1. Health Check:**
```bash
curl http://localhost:8000/health | python3 -m json.tool
```

**2. Tools Verification:**
```bash
curl http://localhost:8000/api/tools | python3 -m json.tool
```

**3. Chat Integration:**
```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"Hello!","context":{"userId":"test","companyId":"test","userName":"Test"}}' \
  | python3 -m json.tool
```

**4. UI Manual Testing:**
Open http://localhost:8000/ui and verify:
- âœ… UI loads correctly
- âœ… Status shows "Connected"
- âœ… Health check succeeds
- âœ… Can send text messages
- âœ… Receives AI responses
- âœ… Voice button visible (ğŸ¤)
- âœ… Microphone permissions work
- âœ… Voice recording functions
- âœ… Transcription works

**5. E2E Testing (Playwright):**
```bash
cd tests/e2e
npm install
npx playwright test wesign-assistant.spec.js
```

**Test Coverage:**
- UI loading and elements
- Text message sending/receiving
- Voice recording button visibility
- Empty message handling
- Health check requests
- Agent routing (filesystem queries)
- Special character safety
- Network request monitoring

**See**: `TEST_RESULTS_REPORT.md` for comprehensive test results with evidence

---

## ğŸ› Troubleshooting

### Problem: "ModuleNotFoundError: No module named 'autogen_agentchat'"

**Solution:**
```bash
cd orchestrator
source venv/bin/activate
pip install autogen-agentchat autogen-core autogen-ext[mcp]
```

### Problem: "Address already in use" (port 8000)

**Solution:**
```bash
# Find and kill process using port 8000
lsof -i :8000 | grep LISTEN | awk '{print $2}' | xargs kill -9

# Or use shorter version
lsof -ti:8000 | xargs kill -9
```

### Problem: OpenAI API Error "Invalid API Key"

**Solution:**
1. Check API key in `.env` is correct
2. Visit https://platform.openai.com/api-keys
3. Generate new key if needed
4. Update `.env` with new key: `OPENAI_API_KEY=sk-proj-YOUR-KEY-HERE`
5. Restart orchestrator: `python main.py`

### Problem: FileSystem MCP Error "Directory not found"

**Solution:**
```bash
# Create required directories
mkdir -p ~/Documents ~/Downloads /tmp/wesign-assistant

# Update .env with correct paths
FILESYSTEM_ALLOWED_DIRS=$HOME/Documents,$HOME/Downloads,/tmp/wesign-assistant

# Restart orchestrator
python main.py
```

### Problem: UI Not Loading

**Solution:**
1. Check server is running: `curl http://localhost:8000/health`
2. Check frontend directory exists: `ls -la frontend/`
3. Verify `chatkit-index.html` exists
4. Check browser console for errors (F12 â†’ Console)
5. Clear browser cache and reload

### Problem: Voice Recording Not Working

**Solution:**
1. Check microphone permissions in browser
2. Verify HTTPS or localhost connection (required for MediaRecorder API)
3. Test microphone in system settings
4. Check browser console for errors
5. Verify OPENAI_API_KEY in `.env`
6. Check backend logs for transcription errors

### Problem: "Transcription failed" Error

**Solution:**
1. Verify OPENAI_API_KEY in `.env` file
2. Check audio file format (WAV, MP3, etc.)
3. Verify file size < 25MB
4. Check backend logs: `python main.py` output
5. Test API directly: `curl -X POST http://localhost:8000/api/speech-to-text`

### Problem: WeSign MCP Shows 0 Tools

**Solution:**
This is expected if WeSign MCP server is not running. To enable:
1. Start WeSign MCP server on port 3000
2. Set `WESIGN_MCP_URL=http://localhost:3000` in `.env`
3. Restart orchestrator
4. Check logs for "âœ… WeSign MCP: X tools available"

**Note**: System continues to work with FileSystem MCP (14 tools) even if WeSign MCP unavailable.

### Problem: Agent Routes to Wrong Specialist

**Solution:**
Be more specific with keywords:
- âœ… "List files in Documents" â†’ FileSystemAgent
- âœ… "Sign this document" â†’ SigningAgent
- âœ… "Show templates" â†’ TemplateAgent
- âŒ "Help with file" â†’ May route to AdminAgent (ambiguous)

**Routing Keywords:**
- FileSystem: "file", "browse", "list files", "read file"
- Signing: "sign", "signature", "signing"
- Template: "template", "templates"
- Document: "upload", "document", "pdf"

---

## ğŸ“Š System Status

**Current Version**: 2.0.0-native-mcp
**MCP Integration**: native_autogen_mcp
**AutoGen Version**: 0.7.5
**Python Version**: 3.9+ (3.12 recommended)
**FastAPI Version**: 0.104+
**OpenAI SDK Version**: 1.0.0+

### Agents Status

- âœ… **DocumentAgent** - Ready (WeSign MCP tools)
- âœ… **SigningAgent** - Ready (WeSign MCP tools)
- âœ… **TemplateAgent** - Ready (WeSign MCP tools)
- âœ… **AdminAgent** - Ready (No tools needed)
- âœ… **FileSystemAgent** - Ready (14 tools available)

### MCP Servers Status

**FileSystem MCP:**
- Status: âœ… Operational
- Type: stdio-based (npx @modelcontextprotocol/server-filesystem)
- Tools: 14 available
- Directories: ~/Documents, ~/Downloads, /tmp/wesign-assistant

**WeSign MCP:**
- Status: âš ï¸ Enabled, awaiting server startup
- Type: HTTP-based (StreamableHttpServerParams)
- URL: http://localhost:3000 (configurable)
- Tools: 0 (will populate when server starts)
- Fallback: Graceful (system continues with FileSystem MCP)

### Voice Features Status

- âœ… Whisper API Integration: Active
- âœ… Speech-to-Text Endpoint: /api/speech-to-text
- âœ… Supported Formats: WAV, MP3, MP4, M4A, MPEG, WEBM
- âœ… Max File Size: 25MB
- âœ… Browser Support: Chrome 47+, Firefox 25+, Edge 79+, Safari 14.1+

---

## ğŸš€ Performance Tips

### For Best Performance

1. **Use appropriate agent routing**:
   - Be specific with keywords to route to correct agent
   - FileSystem queries work best with explicit paths

2. **Optimize file operations**:
   - Keep allowed directories focused (avoid large directories)
   - Use specific file patterns in search queries
   - Read files in chunks for large files

3. **API usage**:
   - Reuse `conversationId` for multi-turn conversations
   - Use health check to verify system before operations
   - Monitor `/api/chatkit-status` for server load

4. **Voice input**:
   - Keep recordings under 60 seconds for fast transcription
   - Speak clearly for better accuracy
   - Use quiet environment to reduce background noise

---

## ğŸ“ Development Notes

### Code Quality

- âœ… No mock implementations - all integrations are real
- âœ… Proper error handling and logging
- âœ… Type hints throughout codebase
- âœ… Comprehensive docstrings
- âœ… Security best practices followed

### Testing Coverage

- âœ… E2E tests with Playwright
- âœ… API endpoint testing
- âœ… MCP integration testing
- âœ… Voice feature testing
- âœ… Agent routing verification

See `TEST_RESULTS_REPORT.md` for detailed test results with evidence.

### Recent Updates

**Latest Commit (b9bd95d):**
- âœ… Enabled WeSign MCP server connection with HTTP support
- âœ… Added StreamableHttpServerParams for HTTP-based MCP
- âœ… Implemented graceful fallback when server unavailable
- âœ… Maintains 14 operational FileSystem MCP tools

**Voice Feature:**
- âœ… Full OpenAI Whisper API integration
- âœ… Browser audio recording with MediaRecorder API
- âœ… Auto-transcription with user review workflow
- âœ… Comprehensive error handling

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/your-feature`
3. Make your changes with clear commits
4. Test thoroughly (manual + E2E)
5. Update documentation if needed
6. Submit a pull request with detailed description

**Areas for Contribution:**
- Additional MCP server integrations
- Enhanced agent capabilities
- UI/UX improvements
- Test coverage expansion
- Performance optimizations
- Documentation improvements

---

## ğŸ“„ License

[Your License Here]

---

## ğŸ”— Links

### Official Documentation
- [AutoGen Documentation](https://microsoft.github.io/autogen/)
- [AutoGen v0.7.5 MCP Integration](https://microsoft.github.io/autogen/docs/packages/autogen-ext/tools/mcp/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
- [OpenAI Whisper API](https://platform.openai.com/docs/guides/speech-to-text)
- [OpenAI ChatKit Python SDK](https://openai.github.io/chatkit-python/)
- [OpenAI ChatKit JavaScript](https://openai.github.io/chatkit-js/)
- [Model Context Protocol](https://modelcontextprotocol.io/)

### Project Documentation
- [Voice Feature Documentation](VOICE_FEATURE_DOCUMENTATION.md)
- [Test Results Report](TEST_RESULTS_REPORT.md)
- [API Documentation](http://localhost:8000/docs) (when server running)

---

## ğŸ’¡ Tips & Best Practices

### For Users

- ğŸ¯ Be specific in your requests to get better responses
- ğŸ“ Organize files in allowed directories for easy access
- ğŸ”„ Use conversation context for multi-step workflows
- âœ… Review tool calls before confirming actions
- ğŸ¤ Use voice input for faster interaction
- ğŸ“ Review transcribed text before sending

### For Developers

- ğŸ“š Read AutoGen v0.7.5 documentation for latest features
- ğŸ”§ Use native MCP when possible (simpler & more reliable)
- ğŸ§ª Test agents individually before integration
- ğŸ“ Keep `.env.example` updated with new variables
- ğŸ” Monitor logs for debugging: `python main.py`
- ğŸ›¡ï¸ Follow security best practices for API keys
- ğŸ“Š Use health endpoint to verify system state

### For Integration

- ğŸŒ Use `/api/chat` for text-based integration
- ğŸ¤ Use `/api/speech-to-text` for voice features
- ğŸ“¡ Monitor `/health` endpoint for system status
- ğŸ”§ Check `/api/tools` to verify available tools
- ğŸ“– Reference `/docs` for OpenAPI specification

---

## ğŸ“ Support & Contact

For issues, questions, or contributions:
1. Check this README thoroughly
2. Review `VOICE_FEATURE_DOCUMENTATION.md` for voice features
3. Check `TEST_RESULTS_REPORT.md` for testing examples
4. Review backend logs: `python main.py` output
5. Check browser console: F12 â†’ Console tab
6. Submit issue with detailed information

---

**Built with â¤ï¸ using AutoGen v0.7.5, OpenAI GPT-4, Whisper API, and Model Context Protocol**

*Last Updated: 2025-10-28*
